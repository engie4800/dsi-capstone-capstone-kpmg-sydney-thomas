{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dad4c90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_openai in /opt/anaconda3/lib/python3.9/site-packages (0.0.7)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/anaconda3/lib/python3.9/site-packages (from langchain_openai) (1.22.4)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /opt/anaconda3/lib/python3.9/site-packages (from langchain_openai) (1.12.0)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.26 in /opt/anaconda3/lib/python3.9/site-packages (from langchain_openai) (0.1.27)\n",
      "Requirement already satisfied: tiktoken<1,>=0.5.2 in /opt/anaconda3/lib/python3.9/site-packages (from langchain_openai) (0.6.0)\n",
      "Requirement already satisfied: anyio<5,>=3 in /opt/anaconda3/lib/python3.9/site-packages (from langchain-core<0.2.0,>=0.1.26->langchain_openai) (3.5.0)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/anaconda3/lib/python3.9/site-packages (from langchain-core<0.2.0,>=0.1.26->langchain_openai) (1.10.12)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /opt/anaconda3/lib/python3.9/site-packages (from langchain-core<0.2.0,>=0.1.26->langchain_openai) (23.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/anaconda3/lib/python3.9/site-packages (from langchain-core<0.2.0,>=0.1.26->langchain_openai) (8.2.3)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /opt/anaconda3/lib/python3.9/site-packages (from langchain-core<0.2.0,>=0.1.26->langchain_openai) (0.1.9)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/lib/python3.9/site-packages (from langchain-core<0.2.0,>=0.1.26->langchain_openai) (2.28.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/lib/python3.9/site-packages (from langchain-core<0.2.0,>=0.1.26->langchain_openai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/lib/python3.9/site-packages (from langchain-core<0.2.0,>=0.1.26->langchain_openai) (6.0)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.9/site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.9/site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.9/site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (0.27.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/lib/python3.9/site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/anaconda3/lib/python3.9/site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.10.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/lib/python3.9/site-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2022.7.9)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.9/site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.26->langchain_openai) (3.3)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.26->langchain_openai) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.26->langchain_openai) (3.9.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.26->langchain_openai) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.26->langchain_openai) (2.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70c9b4f",
   "metadata": {},
   "source": [
    "pip install neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c26baa17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/anaconda3/lib/python3.9/site-packages (0.1.9)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/lib/python3.9/site-packages (from langchain) (2.28.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/lib/python3.9/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/lib/python3.9/site-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/lib/python3.9/site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.26 in /opt/anaconda3/lib/python3.9/site-packages (from langchain) (0.1.27)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /opt/anaconda3/lib/python3.9/site-packages (from langchain) (0.1.9)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/anaconda3/lib/python3.9/site-packages (from langchain) (1.22.4)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.21 in /opt/anaconda3/lib/python3.9/site-packages (from langchain) (0.0.24)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/anaconda3/lib/python3.9/site-packages (from langchain) (1.10.12)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/anaconda3/lib/python3.9/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/lib/python3.9/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/anaconda3/lib/python3.9/site-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (21.4.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/anaconda3/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
      "Requirement already satisfied: anyio<5,>=3 in /opt/anaconda3/lib/python3.9/site-packages (from langchain-core<0.2,>=0.1.26->langchain) (3.5.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /opt/anaconda3/lib/python3.9/site-packages (from langchain-core<0.2,>=0.1.26->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.0->langchain) (3.9.15)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/anaconda3/lib/python3.9/site-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2->langchain) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2->langchain) (1.26.11)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/anaconda3/lib/python3.9/site-packages (from SQLAlchemy<3,>=1.4->langchain) (1.1.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/lib/python3.9/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.26->langchain) (1.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (0.4.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10fa7f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b50e390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: neo4j in /opt/anaconda3/lib/python3.9/site-packages (5.17.0)\n",
      "Requirement already satisfied: pytz in /opt/anaconda3/lib/python3.9/site-packages (from neo4j) (2022.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beff16ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d48f392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "# llm.invoke('How can you connect to Neo4j')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96593664",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Neo4jGraph(\n",
    "    url=\"bolt://localhost:7687\", username=\"neo4j\", password=\"kpmgkpmg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5284ca05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph.query(\n",
    "# \"\"\"\n",
    "# // remove the current relationship \n",
    "# MATCH (n) DETACH DELETE n\n",
    "# \"\"\"\n",
    "# )\n",
    "# graph.refresh_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a7a73f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node properties are the following:\n",
      "report {report_format: STRING, business_group: STRING, name: STRING, entitlements: STRING, maintainers: STRING},section {name: STRING},field {description: STRING, name: STRING},part {name: STRING, description: STRING},model {parameters: STRING, name: STRING, created_at: STRING, author: STRING, version: INTEGER, output_column: STRING, performance_metrics: STRING, input_columns: STRING, metadata: STRING},mapping {report_name: STRING, upstream_source_type: STRING},database {name: STRING},table {name: STRING},column {name: STRING}\n",
      "Relationship properties are the following:\n",
      "\n",
      "The relationships are the following:\n",
      "(:report)-[:HAS_SECTION]->(:section),(:report)-[:REFERS_TO]->(:field),(:section)-[:HAS_FIELD]->(:field),(:field)-[:HAS_PART]->(:part),(:model)-[:HAS_INPUT]->(:column),(:model)-[:FOLLOWS]->(:model),(:mapping)-[:MAP]->(:field),(:mapping)-[:MAP]->(:model),(:mapping)-[:MAP]->(:database),(:database)-[:HAS_TABLE]->(:table),(:table)-[:HAS_COLUMN]->(:column)\n"
     ]
    }
   ],
   "source": [
    "print(graph.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f830d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.refresh_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d76433b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node properties are the following:\n",
      "report {report_format: STRING, business_group: STRING, name: STRING, entitlements: STRING, maintainers: STRING},section {name: STRING},field {description: STRING, name: STRING},part {name: STRING, description: STRING},model {parameters: STRING, name: STRING, created_at: STRING, author: STRING, version: INTEGER, output_column: STRING, performance_metrics: STRING, input_columns: STRING, metadata: STRING},mapping {report_name: STRING, upstream_source_type: STRING},database {name: STRING},table {name: STRING},column {name: STRING}\n",
      "Relationship properties are the following:\n",
      "\n",
      "The relationships are the following:\n",
      "(:report)-[:HAS_SECTION]->(:section),(:report)-[:REFERS_TO]->(:field),(:section)-[:HAS_FIELD]->(:field),(:field)-[:HAS_PART]->(:part),(:model)-[:HAS_INPUT]->(:column),(:model)-[:FOLLOWS]->(:model),(:mapping)-[:MAP]->(:field),(:mapping)-[:MAP]->(:model),(:mapping)-[:MAP]->(:database),(:database)-[:HAS_TABLE]->(:table),(:table)-[:HAS_COLUMN]->(:column)\n"
     ]
    }
   ],
   "source": [
    "print(graph.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92c48a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = GraphCypherQAChain.from_llm(\n",
    "    llm = ChatOpenAI(temperature=0), graph=graph, verbose=True,\n",
    "    model=\"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0a956f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (:section{name:\"Key Takeaways\"})-[:HAS_FIELD]->(field)\n",
      "RETURN field.name\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'field.name': 'External Economic Shocks'}, {'field.name': 'Key Spending Categories'}, {'field.name': 'Government Fiscal Balance Efforts'}, {'field.name': 'Fiscal Indicators'}, {'field.name': 'Domestic Economic Recovery'}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'What are the fields of the section Key Takeaways?',\n",
       " 'result': 'The fields of the section Key Takeaways are External Economic Shocks, Key Spending Categories, Government Fiscal Balance Efforts, Fiscal Indicators, and Domestic Economic Recovery.'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What are the fields of the section Key Takeaways?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01e5773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain.invoke(\"Tell me the Nominal GDP in the report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36327cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explicit use case query\n",
    "# 1. report, 2.model, 3.database\n",
    "# 1. classification: which use case? \n",
    "# 2. can you get the field? -- back&forth with LLM\n",
    "# let LLM to summarize the answer of the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56e69831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user: detail about a specific field \n",
    "# + query template, field to fill in \n",
    "# give few shot example\n",
    "\n",
    "# follow up questions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "172eddd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation of the LLM model\n",
    "# with/ without classification layer --> check the improvement of the middle classification layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a45ef08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Correctness\n",
    "# ground truth: for this query, we want certain section, certain field to perform as the reference of answer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b40b84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Stable\n",
    "# see whether the same query always gives the valid and correct answer \n",
    "# (temperature not equal to 0 to give randomness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5392b309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one model output is another model's input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "679fcbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "\n",
    "def get_user_id() -> int:\n",
    "    \"\"\"\n",
    "    Placeholder for a function that would normally retrieve\n",
    "    a user's ID\n",
    "    \"\"\"\n",
    "    return 1\n",
    "\n",
    "\n",
    "def remove_lucene_chars(text: str) -> str:\n",
    "    \"\"\"Remove Lucene special characters\"\"\"\n",
    "    special_chars = [\n",
    "        \"+\",\n",
    "        \"-\",\n",
    "        \"&\",\n",
    "        \"|\",\n",
    "        \"!\",\n",
    "        \"(\",\n",
    "        \")\",\n",
    "        \"{\",\n",
    "        \"}\",\n",
    "        \"[\",\n",
    "        \"]\",\n",
    "        \"^\",\n",
    "        '\"',\n",
    "        \"~\",\n",
    "        \"*\",\n",
    "        \"?\",\n",
    "        \":\",\n",
    "        \"\\\\\",\n",
    "    ]\n",
    "    for char in special_chars:\n",
    "        if char in text:\n",
    "            text = text.replace(char, \" \")\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def generate_full_text_query(input: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a full-text search query for a given input string.\n",
    "\n",
    "    This function constructs a query string suitable for a full-text search.\n",
    "    It processes the input string by splitting it into words and appending a\n",
    "    similarity threshold (~0.8) to each word, then combines them using the AND\n",
    "    operator. Useful for mapping movies and people from user questions\n",
    "    to database values, and allows for some misspelings.\n",
    "    \"\"\"\n",
    "    full_text_query = \"\"\n",
    "    words = [el for el in remove_lucene_chars(input).split() if el]\n",
    "    for word in words[:-1]:\n",
    "        full_text_query += f\" {word}~0.8 AND\"\n",
    "    full_text_query += f\" {words[-1]}~0.8\"\n",
    "    return full_text_query.strip()\n",
    "\n",
    "\n",
    "candidate_query = \"\"\"\n",
    "CALL db.index.fulltext.queryNodes($index, $fulltextQuery, {limit: $limit})\n",
    "YIELD node\n",
    "RETURN coalesce(node.name, node.title) AS candidate,\n",
    "       [el in labels(node) WHERE el IN ['section'] | el][0] AS label\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_candidates(input: str, type: str, limit: int = 3) -> List[Dict[str, str]]:\n",
    "\n",
    "    ft_query = generate_full_text_query(input)\n",
    "    candidates = graph.query(\n",
    "        candidate_query, {\"fulltextQuery\": ft_query, \"index\": type, \"limit\": limit}\n",
    "    )\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e6eeed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Type\n",
    "\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")\n",
    "\n",
    "# Import things that are needed generically\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import BaseTool\n",
    "\n",
    "description_query = \"\"\"\n",
    "MATCH (s:section)-[:HAS_FIELD]->(f:field)\n",
    "WHERE s.name = $candidate\n",
    "WITH s, collect(f.name + \": \" + f.description) as fields\n",
    "WITH \"Section: \" + s.name + \"\\n\" +\n",
    "     \"Fields: \\n\" + reduce(s=\"\", f IN fields | s + f + \"\\n\") as sectionDetails\n",
    "RETURN sectionDetails\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_information(entity: str, type: str) -> str:\n",
    "    candidates = get_candidates(entity, type)\n",
    "    if not candidates:\n",
    "        return \"No information was found about the movie or person in the database\"\n",
    "    elif len(candidates) > 1:\n",
    "        newline = \"\\n\"\n",
    "        return (\n",
    "            \"Need additional information, which of these \"\n",
    "            f\"did you mean: {newline + newline.join(str(d) for d in candidates)}\"\n",
    "        )\n",
    "    data = graph.query(\n",
    "        description_query, params={\"candidate\": candidates[0][\"candidate\"]}\n",
    "    )\n",
    "    return data[0]\n",
    "\n",
    "\n",
    "class InformationInput(BaseModel):\n",
    "    entity: str = Field(description=\"movie or a person mentioned in the question\")\n",
    "    entity_type: str = Field(\n",
    "        description=\"type of the entity. Available options are 'movie' or 'person'\"\n",
    "    )\n",
    "\n",
    "\n",
    "class InformationTool(BaseTool):\n",
    "    name = \"Information\"\n",
    "    description = (\n",
    "        \"useful for when you need to answer questions about various actors or movies\"\n",
    "    )\n",
    "    args_schema: Type[BaseModel] = InformationInput\n",
    "\n",
    "    def _run(\n",
    "        self,\n",
    "        entity: str,\n",
    "        entity_type: str,\n",
    "        run_manager: Optional[CallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "        return get_information(entity, entity_type)\n",
    "\n",
    "    async def _arun(\n",
    "        self,\n",
    "        entity: str,\n",
    "        entity_type: str,\n",
    "        run_manager: Optional[AsyncCallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        return get_information(entity, entity_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03f7cdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List, Tuple\n",
    "\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.agents.format_scratchpad import format_to_openai_function_messages\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.schema import AIMessage, HumanMessage\n",
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "from langchain_community.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2d05ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `format_tool_to_openai_function` was deprecated in LangChain 0.1.16 and will be removed in 0.2.0. Use langchain_core.utils.function_calling.convert_to_openai_function() instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "tools = [InformationTool()]  # Only include the InformationTool\n",
    "\n",
    "llm_with_tools = llm.bind(functions=[format_tool_to_openai_function(t) for t in tools])\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that finds information about sections. \"\n",
    "            \"If the tool requires follow-up questions, make sure to ask the user \"\n",
    "            \"for clarification. Include any available options that need to be \"\n",
    "            \"clarified in the follow-up questions. Do only the things the user \"\n",
    "            \"specifically requested.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def _format_chat_history(chat_history: List[Tuple[str, str]]):\n",
    "    buffer = []\n",
    "    for human, ai in chat_history:\n",
    "        buffer.append(HumanMessage(content=human))\n",
    "        buffer.append(AIMessage(content=ai))\n",
    "    return buffer\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"chat_history\": lambda x: _format_chat_history(x[\"chat_history\"])\n",
    "        if x.get(\"chat_history\")\n",
    "        else [],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_function_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIFunctionsAgentOutputParser()\n",
    ")\n",
    "\n",
    "# Add typing for input\n",
    "class AgentInput(BaseModel):\n",
    "    input: str\n",
    "    chat_history: List[Tuple[str, str]] = Field(\n",
    "        ..., extra={\"widget\": {\"type\": \"chat\", \"input\": \"input\", \"output\": \"output\"}}\n",
    "    )\n",
    "\n",
    "class Output(BaseModel):\n",
    "    output: Any\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True).with_types(\n",
    "    input_type=AgentInput, output_type=Output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5301fcbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI'm sorry, but I need more information to answer your question. Could you please specify the context in which you are referring to the \"Budget Summary\" section?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'How many fields are there in the section Budget Summary?', 'output': 'I\\'m sorry, but I need more information to answer your question. Could you please specify the context in which you are referring to the \"Budget Summary\" section?'}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    original_query = \"How many fields are there in the section Budget Summary?\"\n",
    "    print(agent_executor.invoke({\"input\": original_query}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60558038",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81af6499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8188976",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
