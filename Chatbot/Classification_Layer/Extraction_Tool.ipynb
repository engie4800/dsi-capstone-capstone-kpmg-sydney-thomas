{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/anaconda3/lib/python3.9/site-packages (0.1.12)\n",
      "Requirement already satisfied: openai in /opt/anaconda3/lib/python3.9/site-packages (1.12.0)\n",
      "Requirement already satisfied: neo4j in /opt/anaconda3/lib/python3.9/site-packages (5.17.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/anaconda3/lib/python3.9/site-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/lib/python3.9/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.31 in /opt/anaconda3/lib/python3.9/site-packages (from langchain) (0.1.32)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/lib/python3.9/site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/anaconda3/lib/python3.9/site-packages (from langchain) (0.1.26)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/anaconda3/lib/python3.9/site-packages (from langchain) (1.10.12)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.28 in /opt/anaconda3/lib/python3.9/site-packages (from langchain) (0.0.28)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/lib/python3.9/site-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /opt/anaconda3/lib/python3.9/site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/anaconda3/lib/python3.9/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/anaconda3/lib/python3.9/site-packages (from langchain) (1.22.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/lib/python3.9/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/lib/python3.9/site-packages (from langchain) (2.28.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.9/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/lib/python3.9/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.9/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/anaconda3/lib/python3.9/site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.9/site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.9/site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: pytz in /opt/anaconda3/lib/python3.9/site-packages (from neo4j) (2022.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (21.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (3.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/anaconda3/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /opt/anaconda3/lib/python3.9/site-packages (from langchain-core<0.2.0,>=0.1.31->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.9.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2->langchain) (1.26.11)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/anaconda3/lib/python3.9/site-packages (from SQLAlchemy<3,>=1.4->langchain) (1.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (0.4.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain openai neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict, Optional\n",
    "from typing import Any, List, Tuple\n",
    "from typing import Optional, Type\n",
    "\n",
    "from langchain.graphs import Neo4jGraph\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.agents.format_scratchpad import format_to_openai_function_messages\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.schema import AIMessage, HumanMessage\n",
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")\n",
    "# Import things that are needed generically\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import BaseTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = \"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\"\n",
    "\n",
    "graph = Neo4jGraph(\n",
    "    url=\"bolt://localhost:7687\", username=\"neo4j\", password=\"kpmgkpmg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Assuming 'graph' is an initialized graph database connection\n",
    "\n",
    "def generate_full_text_query(input: str) -> str:\n",
    "    full_text_query = \"\"\n",
    "    words = input.split()\n",
    "    for word in words[:-1]:\n",
    "        full_text_query += f\" {word}~0.8 AND\"\n",
    "    full_text_query += f\" {words[-1]}~0.8\"\n",
    "    return full_text_query.strip()\n",
    "\n",
    "candidate_query = \"\"\"\n",
    "CALL db.index.fulltext.queryNodes($index, $fulltextQuery)\n",
    "YIELD node\n",
    "RETURN coalesce(node.name, node.title) AS candidate, [el in labels(node) WHERE el IN ['section', 'model'] | el][0] AS label\n",
    "LIMIT toInteger($limit)\n",
    "\"\"\"\n",
    "\n",
    "description_query = \"\"\"\n",
    "MATCH (entity)\n",
    "WHERE entity.name = $candidate AND ('section' IN labels(entity) OR 'model' IN labels(entity))\n",
    "WITH entity, \n",
    "     CASE WHEN 'model' IN labels(entity) THEN 'model'\n",
    "          WHEN 'section' IN labels(entity) THEN 'section'\n",
    "          ELSE 'unknown'\n",
    "     END as entityType\n",
    "OPTIONAL MATCH (entity)-[r]-(related)\n",
    "WITH entity, entityType, \n",
    "     CASE WHEN entityType = 'model' THEN collect({relation: type(r), relatedNode: related.name})\n",
    "          ELSE []\n",
    "     END as modelRelations,\n",
    "     CASE WHEN entityType = 'section' THEN collect({relation: type(r), relatedNode: related.name})\n",
    "          ELSE []\n",
    "     END as sectionRelations\n",
    "RETURN \n",
    "    CASE \n",
    "        WHEN entityType = 'model' THEN \n",
    "            'Type: ' + entityType + '\\nName: ' + entity.name + \n",
    "            '\\nAuthor: ' + entity.author +\n",
    "            '\\nCreated At: ' + entity.created_at +\n",
    "            '\\nInput Columns: ' + entity.input_columns + \n",
    "            '\\nOutput Columns: ' + entity.output_column +\n",
    "            '\\nParameters: ' + entity.parameters + \n",
    "            '\\nPerformance Metrics: ' + entity.performance_metrics\n",
    "        WHEN entityType = 'section' THEN\n",
    "            'Type: ' + entityType + '\\nName: ' + entity.name\n",
    "        ELSE 'Entity type not recognized.'\n",
    "    END as context\n",
    "LIMIT 1\n",
    "\"\"\"\n",
    "\n",
    "def classify_query(input: str) -> str:\n",
    "    if \"model\" in input:\n",
    "        return \"model\"\n",
    "    elif \"section\" in input or \"fields\" in input:\n",
    "        return \"section\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "def get_candidates(input: str, type: str, limit: int = 3) -> List[Dict[str, str]]:\n",
    "    ft_query = generate_full_text_query(input)\n",
    "    candidates = graph.query(candidate_query, {'fulltextQuery': ft_query, 'index': type, 'limit': limit})\n",
    "    return candidates\n",
    "\n",
    "def get_information(entity: str, query_type:str) -> str:\n",
    "    type = classify_query(query_type)\n",
    "    if type == \"unknown\":\n",
    "        return \"Query classification failed. Please provide more specific information.\"\n",
    "    \n",
    "    candidates = get_candidates(entity, type)\n",
    "    if not candidates:\n",
    "        return \"No information was found about the section or model in the database\"\n",
    "    elif len(candidates) > 1:\n",
    "        newline = '\\n'\n",
    "        return f\"Need additional information, which of these did you mean: {newline + newline.join(str(d) for d in candidates)}\"\n",
    "    data = graph.query(\n",
    "        description_query, params={\"candidate\": candidates[0]['candidate']}\n",
    "    )\n",
    "    return data[0][\"context\"]\n",
    "\n",
    "# Update the InformationInput and InformationTool classes as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: section\n",
      "Name: Budget Summary\n"
     ]
    }
   ],
   "source": [
    "print(get_information(\"Budget Summary\", \"section\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: model\n",
      "Name: model_782951116\n",
      "Author: [\"Alex\", \"Martin\"]\n",
      "Created At: 2024-02-12T20:59:17Z\n",
      "Input Columns: [\"revenue\", \"cost\", \"profitMargin\", \"tax_col\"]\n",
      "Output Columns: revenue\n",
      "Parameters: [{name: \"example_parameter\", value: 77}]\n",
      "Performance Metrics: [\n",
      "    {name: \"mean absolute error\", value: 10228},\n",
      "    {name: \"root mean squared error\", value: 101},\n",
      "    {name: \"R-squared\", value: 0.95}\n",
      "  ]\n"
     ]
    }
   ],
   "source": [
    "print(get_information(\"model_782951116\", \"model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InformationInput(BaseModel):\n",
    "    entity: str = Field(description=\"movie or a person mentioned in the question\")\n",
    "    entity_type: str = Field(\n",
    "        description=\"type of the entity. Available options are 'movie' or 'person'\"\n",
    "    )\n",
    "\n",
    "\n",
    "class InformationTool(BaseTool):\n",
    "    name = \"Information\"\n",
    "    description = (\n",
    "        \"useful for when you need to answer questions about various actors or movies\"\n",
    "    )\n",
    "    args_schema: Type[BaseModel] = InformationInput\n",
    "\n",
    "    def _run(\n",
    "        self,\n",
    "        entity: str,\n",
    "        entity_type: str,\n",
    "        run_manager: Optional[CallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "        return get_information(entity, entity_type)\n",
    "\n",
    "    async def _arun(\n",
    "        self,\n",
    "        entity: str,\n",
    "        entity_type: str,\n",
    "        run_manager: Optional[AsyncCallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        return get_information(entity, entity_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "tools = [InformationTool()]  # Only include the InformationTool\n",
    "\n",
    "llm_with_tools = llm.bind(functions=[format_tool_to_openai_function(t) for t in tools])\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that finds information about sections. \"\n",
    "            \"If the tool requires follow-up questions, make sure to ask the user \"\n",
    "            \"for clarification. Include any available options that need to be \"\n",
    "            \"clarified in the follow-up questions. Do only the things the user \"\n",
    "            \"specifically requested.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def _format_chat_history(chat_history: List[Tuple[str, str]]):\n",
    "    buffer = []\n",
    "    for human, ai in chat_history:\n",
    "        buffer.append(HumanMessage(content=human))\n",
    "        buffer.append(AIMessage(content=ai))\n",
    "    return buffer\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"chat_history\": lambda x: _format_chat_history(x[\"chat_history\"])\n",
    "        if x.get(\"chat_history\")\n",
    "        else [],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_function_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIFunctionsAgentOutputParser()\n",
    ")\n",
    "\n",
    "# Add typing for input\n",
    "class AgentInput(BaseModel):\n",
    "    input: str\n",
    "    chat_history: List[Tuple[str, str]] = Field(\n",
    "        ..., extra={\"widget\": {\"type\": \"chat\", \"input\": \"input\", \"output\": \"output\"}}\n",
    "    )\n",
    "\n",
    "class Output(BaseModel):\n",
    "    output: Any\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True).with_types(\n",
    "    input_type=AgentInput, output_type=Output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Information` with `{'entity': 'model_782951116', 'entity_type': 'model'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mType: model\n",
      "Name: model_782951116\n",
      "Author: [\"Alex\", \"Martin\"]\n",
      "Created At: 2024-02-12T20:59:17Z\n",
      "Input Columns: [\"revenue\", \"cost\", \"profitMargin\", \"tax_col\"]\n",
      "Output Columns: revenue\n",
      "Parameters: [{name: \"example_parameter\", value: 77}]\n",
      "Performance Metrics: [\n",
      "    {name: \"mean absolute error\", value: 10228},\n",
      "    {name: \"root mean squared error\", value: 101},\n",
      "    {name: \"R-squared\", value: 0.95}\n",
      "  ]\u001b[0m\u001b[32;1m\u001b[1;3mThe performance metrics of model_782951116 are:\n",
      "- Mean Absolute Error: 10228\n",
      "- Root Mean Squared Error: 101\n",
      "- R-squared: 0.95\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What is the performance metrics of the model model_782951116?', 'output': 'The performance metrics of model_782951116 are:\\n- Mean Absolute Error: 10228\\n- Root Mean Squared Error: 101\\n- R-squared: 0.95'}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #original_query = \"What do you know about the model model_782951116?\"\n",
    "    original_query = \"What is the performance metrics of the model model_782951116?\"\n",
    "    print(agent_executor.invoke({\"input\": original_query}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Information` with `{'entity': 'Global Economic Outlook - December 2023', 'entity_type': 'report'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mQuery classification failed. Please provide more specific information.\u001b[0m\u001b[32;1m\u001b[1;3mI'm sorry, but I couldn't retrieve the specific models used in the report \"Global Economic Outlook - December 2023.\" If you have any other specific questions or details you'd like me to look into, please let me know!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'what models are used in the report Global Economic Outlook - December 2023？', 'output': 'I\\'m sorry, but I couldn\\'t retrieve the specific models used in the report \"Global Economic Outlook - December 2023.\" If you have any other specific questions or details you\\'d like me to look into, please let me know!'}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #original_query = \"What do you know about the model model_782951116?\"\n",
    "    original_query = \"what predictive models are used in the report Global Economic Outlook - December 2023？\"\n",
    "    print(agent_executor.invoke({\"input\": original_query}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
